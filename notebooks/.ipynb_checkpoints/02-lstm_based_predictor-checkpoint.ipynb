{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Convolution2D, Merge, MaxPooling2D, Flatten\n",
    "from keras.models import model_from_json\n",
    "from lstm_based_predictor.model import GlobalConfig, ModelConfig, Model\n",
    "from lstm_based_predictor.data import Dataset, MODEL_TRAINING_DIR\n",
    "from lstm_based_predictor.load import BatchGenerator\n",
    "from lstm_based_predictor.utils import map_event_type, map_event_type, meta_object\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_info = meta_object\n",
    "event_types = meta_info['event_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lstm_based_predictor.utils import event_weight_dict as output_label_weight_dict\n",
    "\n",
    "weight_dict = {event_types[i] : output_label_weight_dict[i] for i in event_types.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as the first layer in a Sequential model\n",
    "model = Sequential()\n",
    "# model.add(Dense(output_dim=ModelConfig.rnn_size, input_dim=ModelConfig.num_features))\n",
    "# model.add(Activation(\"relu\"))\n",
    "model.add(LSTM(ModelConfig.rnn_size, input_shape=(ModelConfig.seq_length, ModelConfig.num_features)))\n",
    "# model.add(Dense(output_dim=ModelConfig.num_events, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "final_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this segment ONLY if want to add CNN late fusion !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right_branch = Sequential()\n",
    "right_branch.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(11, 144, 7)))\n",
    "model.add(Activation('relu'))\n",
    "#right_branch.add(Convolution2D(8, 3, 3, border_mode='same'))\n",
    "right_branch.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "right_branch.add(Flatten())\n",
    "right_branch.add(Dense(ModelConfig.rnn_size))\n",
    "merged = Merge([model, right_branch], mode='concat')\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.add(Dense(ModelConfig.num_events, activation='softmax'))\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and check how the data looks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading dataset.\")\n",
    "dataset = Dataset(data_directory=os.path.expanduser(\"~/tmp/keras-lstm-data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(dataset.valid_set().tensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.train_set().tl_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Setting up BatchGenerator\")\n",
    "batch_generator = BatchGenerator(dataset, GlobalConfig.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator and batch generator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_rand = ModelConfig.SEED\n",
    "\n",
    "def generate_fixed_batch_set(batch_generator, valid_rand=None, reporting_train=False):\n",
    "    #x_batch_set, y_batch_set = [], []\n",
    "    x_batch_set, y_batch_set= [], []\n",
    "    random.seed(valid_rand)\n",
    "    for b in range(GlobalConfig.num_batches):\n",
    "        random_state = random.getstate()\n",
    "        if reporting_train:\n",
    "            x, y = batch_generator.create_batch('train', random_state=random_state)\n",
    "        else:\n",
    "            x, y = batch_generator.create_batch('valid', random_state=random_state)\n",
    "        x_batch_set += [x]\n",
    "        y_batch_set += [y]\n",
    "    return x_batch_set, y_batch_set\n",
    "\n",
    "test_x, test_y = generate_fixed_batch_set(batch_generator=batch_generator, valid_rand=valid_rand,\n",
    "                                                  reporting_train=False)\n",
    "train2_x, train2_y = generate_fixed_batch_set(batch_generator=batch_generator, valid_rand=1,\n",
    "                                                  reporting_train=True)\n",
    "\n",
    "\n",
    "# Flatten data from batch boxes into straight vectors to get predictions\n",
    "\n",
    "test_x_flattened = np.array(test_x).reshape([-1, np.array(test_x).shape[-2], np.array(test_x).shape[-1]])\n",
    "test_y_flattened = np.array([np.eye(ModelConfig.num_events)[k] for k in np.array(test_y)[:,0,:]]).reshape([-1,\n",
    "                                                                                             ModelConfig.num_events])\n",
    "\n",
    "train2_x_flattened = np.array(train2_x).reshape([-1, np.array(train2_x).shape[-2], np.array(train2_x).shape[-1]])\n",
    "train2_y_flattened = np.array([np.eye(ModelConfig.num_events)[k] for k in np.array(train2_y)[:,0,:]]).reshape([-1,\n",
    "                                                                                             ModelConfig.num_events])\n",
    "\n",
    "\n",
    "\n",
    "#### _h stands for heatmap info\n",
    "# def generate_fixed_batch_set(batch_generator, valid_rand=None, reporting_train=False):\n",
    "#     #x_batch_set, y_batch_set = [], []\n",
    "#     x_batch_set, y_batch_set, x_h_batch_set = [], [], []\n",
    "#     random.seed(valid_rand)\n",
    "#     for b in range(GlobalConfig.num_batches):\n",
    "#         random_state = random.getstate()\n",
    "#         if reporting_train:\n",
    "#             x, y, x_h = batch_generator.create_batch('train', random_state=random_state)\n",
    "#         else:\n",
    "#             x, y, x_h = batch_generator.create_batch('valid', random_state=random_state)\n",
    "#         x_batch_set += [x]\n",
    "#         y_batch_set += [y]\n",
    "#         x_h_batch_set += [np.array(x_h)]\n",
    "#     return x_batch_set, y_batch_set, x_h_batch_set\n",
    "\n",
    "# test_x, test_y = generate_fixed_batch_set(batch_generator=batch_generator, valid_rand=valid_rand,\n",
    "#                                                   reporting_train=False)\n",
    "# train2_x, train2_y = generate_fixed_batch_set(batch_generator=batch_generator, valid_rand=1,\n",
    "#                                                   reporting_train=True)\n",
    "\n",
    "# test_x_flattened = np.array(train2_x_h).reshape([-1, np.array(train2_x_h).shape[-3], \n",
    "# np.array(train2_x_h).shape[-2], np.array(train2_x_h).shape[-1]])\n",
    "\n",
    "# test_x_flattened = np.array(test_x_h).reshape([-1, np.array(test_x_h).shape[-3], np.array(test_x_h).shape[-2], \n",
    "# np.array(test_x_h).shape[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "def generate_data(batch_generator):\n",
    "    while 1:\n",
    "        # create Numpy arrays of input data\n",
    "        # and labels, from each line in the file\n",
    "        x, y= batch_generator.create_batch('train', random_state=random.getstate())\n",
    "        #for i in range(len(x)):\n",
    "        yield (x,np.array([np.eye(ModelConfig.num_events)[k] for k in y[0]]))\n",
    "\n",
    "    \n",
    "# def generate_data(batch_generator):\n",
    "#     while 1:\n",
    "#         # create Numpy arrays of input data\n",
    "#         # and labels, from each line in the file\n",
    "#         x, y, x_hm = batch_generator.create_batch('train', random_state=random.getstate())\n",
    "#         #for i in range(len(x)):\n",
    "#         yield ([x, np.array(x_hm)],np.array([np.eye(ModelConfig.num_events)[k] for k in y[0]]))    \n",
    "\n",
    "#model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
    "#        samples_per_epoch=10000, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next(generate_data(batch_generator))\n",
    "\n",
    "# an (X_sample, y_sample) tuple printed below, where y consists of one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print next(generate_data(batch_generator))[0].shape\n",
    "print next(generate_data(batch_generator))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_generator.create_batch('train', random_state=random.getstate())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generate_data(batch_generator), nb_epoch=200, verbose=1, callbacks=[],\n",
    "                    samples_per_epoch=GlobalConfig.num_batches*GlobalConfig.batch_size, \n",
    "                    validation_data=(test_x_flattened, test_y_flattened), \n",
    "                    nb_val_samples=None, class_weight=None, max_q_size=100, \n",
    "                    nb_worker=1, pickle_safe=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict_proba(test_x_flattened, batch_size=32, verbose=1)\n",
    "# test_pred = model.predict_proba(train2_x_flattened, batch_size=32, verbose=1)\n",
    "# test_pred = model.predict_proba([tttr, tttr_h], batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = [np.argmax(k) for k in test_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis on results in the form of confusion matrix, accuracy numbers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm):\n",
    "    ##text = str(np.float(np.sum(np.diag(cmm))) / np.sum(np.sum(cmm)))\n",
    "    #cm = CF_list[iteri]\n",
    "    text = ''\n",
    "    #plt.figure(figsize = (6,6))\n",
    "    fig, ax = plt.subplots(figsize=(6, 6),\n",
    "                           subplot_kw={'axisbg':'#EEEEEE',\n",
    "                                       'axisbelow':True})\n",
    "    ax.imshow(cm, interpolation='nearest')\n",
    "    #ax.title(text)\n",
    "    #ax.colorbar()\n",
    "    tick_marks = np.arange(np.unique(targets).size)\n",
    "#     plt.xticks(tick_marks, np.unique(labels), rotation=30, size = 7)\n",
    "#     plt.yticks(tick_marks, np.unique(labels), size = 7)\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(np.unique(targets), rotation=60, size = 7)\n",
    "    ax.set_yticklabels(np.unique(targets), size = 7)\n",
    "    #ax.autoscale(enable=True, axis='both', tight=True)\n",
    "    #ax.set_ylabel('True label')\n",
    "    #ax.set_xlabel('Predicted label')\n",
    "    #plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# meta_file_path = '/sentiance/data/meta.npy'\n",
    "\n",
    "# meta_info = np.load(meta_file_path)\n",
    "event_types = meta_info['event_types']\n",
    "labels_dict = {v : k for (k,v) in event_types.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "targets = np.array(test_y)[:,0,:].reshape([-1])\n",
    "targets = [labels_dict[k] for k in targets]\n",
    "predictions = np.array(test_pred).reshape([-1])\n",
    "predictions = [labels_dict[k] for k in predictions]\n",
    "CF = confusion_matrix(targets, predictions, labels=np.unique(targets))\n",
    "CF = CF.astype('float') / CF.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_confusion_matrix(CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.diag(CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.diag(CF).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case we want to merge subclasses to see final 6-class CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funnel them down\n",
    "predictions = [map_event_type(p) for p in predictions]\n",
    "targets = [map_event_type(t) for t in targets]\n",
    "CF = confusion_matrix(targets, predictions, labels=np.unique(targets))\n",
    "CF = CF.astype('float') / CF.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_confusion_matrix(CF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
